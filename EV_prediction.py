# -*- coding: utf-8 -*-
"""EV_Prediction_SZ.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j-y3E1hhTHUSwtiJTmE-Z0atnUOKKvOR

# Electric Vehicle Adoption 

● Industry: auto industry <br>
● Business problem: The electric vehicle (EV) industry is booming, large and small players like GM, Tesla, Hyundai, Toyota are all racing to develop the latest technology to power EVs and the most attractive EVs. Governments are also encouraging EV penetration as a means to combat climate change, and providing incentives to companies and consumers to make the switch. How can we help encourage more people to join the movement, help companies understand their customer base and make strategic business decisions. 
<br>
● Specific problem : Predict if a person will buy an electric vehicle (EV). What are the characteristics of a person or household that are more likely to switch to an EV? 
<br>
● Why does this problem matter? Identifying groups that are more likely to switch to EVs help companies optimize their marketing. This also has broader implications for energy policy and climate change initiatives.
<br>
● What are the datasets that you will consider to solve this problem?<br>
Dataset: National Household Travel Survey <br>
Description: 4 datasets covers persons, household, trip, and vehicle info which contains variables for transport and demographics of people and households <br>
Major variables: vehicle type, age, income, education <br>
Collection method: A national survey of the US conducted up to 2017

### Preliminaries
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# imports and setup

#For system info
import os
#For data crunching
import numpy as np
from numpy.random import default_rng
import pandas as pd

#For plotting:
from matplotlib import pyplot as plt
import matplotlib
import seaborn as sns
# %matplotlib inline
plt.style.use('seaborn') # pretty matplotlib plots
from sklearn.preprocessing import LabelEncoder

#for stats
from scipy.stats import chisquare,chi2_contingency
import scipy.stats as stats

#for ML
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
import statsmodels.api as sm
from sklearn.linear_model import LogisticRegression
#import xgboost as xgb

from sklearn.metrics import roc_curve, roc_auc_score, log_loss, confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score
from sklearn import svm

# import library & check version number
import imblearn
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline
from matplotlib import pyplot
from collections import Counter
#print(imblearn.__version__)

from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB


from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.metrics import confusion_matrix
# grid search
from sklearn.model_selection import RandomizedSearchCV

"""### Load datasets"""

#Data dictionary
dictionary = pd.read_csv('/content/drive/My Drive/DS4A_Women/EV_data/dictionary_v1_2.csv')
#Household data
households = pd.read_csv('/content/drive/My Drive/DS4A_Women/EV_data/hhpub.csv')
#Vehicle data
vehicle = pd.read_csv('/content/drive/My Drive/DS4A_Women/EV_data/vehpub.csv')
#Personal data
persons = pd.read_csv('/content/drive/My Drive/DS4A_Women/EV_data/perpub.csv')
#Trip data
#trips = pd.read_csv('/content/drive/My Drive/DS4A_Women/EV_data/trippub.csv')

#Data codebook
code_files=['/content/drive/My Drive/DS4A_Women/EV_data/codebook_HH.csv',
            '/content/drive/My Drive/DS4A_Women/EV_data/codebook_PER.csv',
            '/content/drive/My Drive/DS4A_Women/EV_data/codebook_VEH.csv']
codebook = pd.concat((pd.read_csv(f) for f in code_files)).reset_index(drop=True)

# Fuel Stations Data
#Data contains the total number of charging stations in each state (assumed to be updated for 2017)
charging_stations = pd.read_csv('/content/drive/My Drive/DS4A_Women/EV_data/alt_fuel_stations.csv')

"""### Clean the codebook of information about variables"""

#Look at the NaN counts (leftover from empty cells that were merged in the excel file)
codebook.isna().sum(axis = 0)

#We need to fill the NaN's. Forward fill the columns (which were merged cells in the excel)
fill_cols=['Name', 'Label','Type', 'Length']
df=codebook.copy()
for column in fill_cols:
    df[column]=df[column].fillna(method='ffill', axis=0)

#Check which rows have NaN
df.isnull().sum(axis = 0)
rows_with_nan = [index for index, row in df.iterrows() if row.isnull().any()]
print(rows_with_nan)
print(df.iloc[rows_with_nan])

# Codebook has a Code/Range column that needs to be split on '=' 
# new data frame with split value columns
new = df["Code / Range"].str.split("=", n = 1, expand = True)
  
# making separate first name column from new data frame
df["Code"]= new[0]
  
# making separate last name column from new data frame
df["Meaning"]= new[1]
  
# Dropping old Name columns
df.drop(columns =["Code / Range"], inplace = True)
# Replace old codebook with new
codebook_clean=df#.apply(pd.to_numeric)#, errors='ignore')
#codebook_clean[['Type', 'Frequency','Weighted','Code']] = df[['Type', 'Frequency','Weighted','Code']].astype(float)  
#Display new codebook
codebook_clean.head()
#codebook_clean.unique

"""### Look at the number of observations and variables per dataset"""

datasets=[households,vehicle,persons]
pd.DataFrame({'dataset':['households','vehicle','persons'],
              'variables':[set.shape[1] for set in datasets],
              'observations':[set.shape[0] for set in datasets]})

"""### Create an accessible data dictionary"""

df=dictionary.copy()
df=df.drop(['Type','Length','HH','PER','VEH'],axis=1)
data_dict=df.set_index('Name')['Label'].to_dict()

print('Total variables:',len(data_dict.values()))

"""### Look at variables labels"""

#Vehicle variables
#[dictionary.loc[dictionary.Name==i,'Label'].values[0] for i in vehicle]
# vehicle_vars=[data_dict.get(i) for i in vehicle]
# vehicle_vars

#person variables
# person_vars=[data_dict.get(i) for i in persons]
# person_vars

#household variables
# house_vars=[data_dict.get(i) for i in households]
# house_vars

"""### Look at vehicel summary statistics """

#vehicle.describe()

"""### Filter and Subsetting the Vehicle Data

We want to look at only the last 3 years: 2015,2016,2017 of vehicle models (new cars) to capture recent trends
Note: this reduces our date from 256115 vehicle data points to 33981 data points, or keeps only 13.3% of vehicle data
"""

# Keep last three years of survey data to identify trends
years = [2017, 2016, 2015]
vehicle = vehicle[vehicle['VEHYEAR'].isin(years)]

# Filter vehicle age to 3 years to illustrate the vehicle adoption trend and potential vehicle market
age = [1,2,3]
vehicle = vehicle[vehicle['VEHAGE'].isin(age)]

# Keep only valid responses
# 'Skip' Response was kept because that was a bulk of the responses
vehicle_type = [4,3,2,1,97,-1]
vehicle = vehicle[vehicle['HFUEL'].isin(vehicle_type)]
print('Length of Data:', len(vehicle))

codebook_clean[codebook_clean['Name'] == 'HFUEL']

"""### Identify Electric Vehicles (EV)

Variable of Interest is 'HFUEL': codes what type of fuel the vehicle uses. 
EV includes the BEV and PHEV (plug in hybrid)  that use the battery. We can look at fully electric only (03-BEV) or all EVs (02,03,04)<br>
- 02	Plug-in Hybrid (gas/electric e.g., Chevy Volt)	
- 03	Electric (e.g. Nissan Leaf)	
- 04	Hybrid (gas/electric, not plug-in e.g., Toyota Prius)
<br>
There are 607 BEV in the data, 482 PHEV and  4996 not plug in hybrid
"""

vehicle = vehicle.reset_index(drop=True)

ev = [4,3,2]
print('% BEV in data',100*len(vehicle[vehicle['HFUEL']==3])/vehicle['HFUEL'].value_counts().sum())
print('% EV in data',100*len(vehicle[vehicle['HFUEL'].isin(ev)])/vehicle['HFUEL'].value_counts().sum())

# Classify our target variable
vehicle['HFUEL_target'] = np.where(vehicle['HFUEL'].isin(ev),1,0)
vehicle['HFUEL_target'].value_counts()
vehicle = vehicle.drop(columns = 'HFUEL')

print(vehicle.shape)
vehicle['HFUEL_target'].value_counts()

"""### Merge NHS dataset on 'HOUSEID' and 'PERSONID' variables """

# Merging our Person, Vehicle, Household datasets
houseid = vehicle['HOUSEID'].unique()
persons = persons[persons['HOUSEID'].isin(houseid)].reset_index(drop = True)
households = households[households['HOUSEID'].isin(houseid)].reset_index(drop = True)
df_all = vehicle.merge(persons, on=['HOUSEID','PERSONID'], how = 'left')
df_all = df_all.merge(households, on = ['HOUSEID'], how = 'left')

"""### Selecting key variables to investigate"""

# Variables we chose as a group
variables_all =[
'Odometer Reading',
'Vehicle Main Driver',
'Home Ownership',
'Count of household members',
'Count of household vehicles',
'Household income',
'Number of drivers in household',
'Household state',
'State FIPS for household address',
'Count of adult household members at least 18 years old',
'Number of workers in household',
'Self-reported annualized mile estimate',
'Urban area size where home address is located',
'Household in urban/rural area',
'Race of household respondent',
'Hispanic status of household respondent',
'Household Identifier',
'Person Identifier',
'Household Vehicle Identifier Used on Trip',
'Annualized fuel cost in US cents per equivalent gallon',
"Category of population density (persons per square mile) in the census block group of the household's home location",
'Annual fuel consumption in US gallons',
'Annual fuel expenditures in US dollars',
'Age (imputed)',
'Educational Attainment',
'Hispanic or Latino Origin',
'Relationship', 
'Gender (imputed)',
'Race',
'Primary Activity in Previous Week',
'Full-Time or Part-Time Worker',
'Mode to Work',
'Job Category',
'Student Status',
'Count of Walk Trips',
'Count of Walk Trips for Exercise',
'Count of Bike Trips',
'Count of Bike Trips for Exercise',
'Count of Bike Share Program Usage',
'Count of Public Transit Usage',
'Count of Motorcycle or Moped Trips',
'Count of Car Share Program Usage',
'Count of Rideshare App Usage',
'Count of People in Vehicle to Work',
'Trip Time to Work in Minutes',
'Option of Working from Home',
'Opinion of Health',
"Road network distance, in miles, between respondent's home location and work location, sourced using Google Distance Matrix API (https://maps.googleapis.com/maps/api/distancematrix/)",
'Level of Physical Activity',
'Frequency of internet use',
'Price of Gasoline Affects Travel',
'Travel is a Financial Burden',
'MSA heavy rail status for household']

# Looking at Invalid Responses using all the variables we chose. Variables were dropped based off of high prorportion of invalid responses.
vars_all = list()
for i in range(len(variables_all)):
    var = list(data_dict.keys())[list(data_dict.values()).index(variables_all[i])]
    vars_all.append(var)
final_dat_var_all = df_all[vars_all]
invalid = [-8, -7, -1, -9, 97,-77,-88,'-8', '-7', '-1', '-9', '97','-77','-88']
invalid_responses = final_dat_var_all.isin(invalid).sum().to_frame()
invalid_var=(invalid_responses[invalid_responses[0] >200]).T.columns
(invalid_responses[invalid_responses[0] >200])

# Reassessing more variables
reassess = ['Level of Physical Activity', 
'Frequency of internet use', 
'Relationship']

reassess_var = list()

for i in range(len(reassess)):
    var = list(data_dict.keys())[list(data_dict.values()).index(reassess[i])]
    vars_all.append(var)
    reassess_var.append(var)
reassess_var
#vars_all

vars_final=list(set(vars_all)-set(invalid_var))#+set(reassess_var)
vars_final

variables =[
#'Odometer Reading',
#'Vehicle Main Driver',
'Home Ownership',
#'Count of household members',
'Count of household vehicles',
'Household income',
#'Number of drivers in household',
'Household state',
#'State FIPS for household address',
#'Count of adult household members at least 18 years old',
'Number of workers in household',
# 'Self-reported annualized mile estimate', ####5719 invalid responses
'Urban area size where home address is located', 
#'Household in urban/rural area', 
#'Race of household respondent',
#'Hispanic status of household respondent',
'Household Identifier',
'Person Identifier', #PERSONID is number 1-10 to identify person in HOUSEID
#'Household Vehicle Identifier Used on Trip',
'Annualized fuel cost in US cents per equivalent gallon',
#"Category of population density (persons per square mile) in the census block group of the household's home location",
#'Annual fuel consumption in US gallons',
#'Annual fuel expenditures in US dollars',
'Age (imputed)', 
'Educational Attainment',
#'Hispanic or Latino Origin',
#'Relationship',  #SZ: reassess, dropped because it's the relationship of someone to person 01, not indication or marital status
'Gender (imputed)',
'Race',
# 'Primary Activity in Previous Week', ##### 1238 invalid responses
#'Full-Time or Part-Time Worker',
#'Mode to Work',
#'Job Category', ####13104 MISSING/INVALID VALUES
#'Student Status',
#'Count of Walk Trips',
#'Count of Walk Trips for Exercise',
#'Count of Bike Trips',
#'Count of Bike Trips for Exercise',
#'Count of Bike Share Program Usage',
#'Count of Public Transit Usage',
#'Count of Motorcycle or Moped Trips',
#'Count of Car Share Program Usage', #### want to focus on the rideshare app instead of other counts of other trans means.
'Count of Rideshare App Usage',
#'Count of People in Vehicle to Work',
#'Trip Time to Work in Minutes',
#'Option of Working from Home',
#'Opinion of Health',
#"Road network distance, in miles, between respondent's home location and work location, sourced using Google Distance Matrix API (https://maps.googleapis.com/maps/api/distancematrix/)",
'Level of Physical Activity', #SZ: reassess
'Frequency of internet use', #SZ: reassess
'Price of Gasoline Affects Travel']
#'Travel is a Financial Burden'
#'MSA heavy rail status for household'

"""Variables commented out were dropped due to one of these reasons:
1. Heatmap shows high correlation between another variable (< 0.7)
2. There is a similar variable with another variable in the list (i.e. HH Race and other race indicators)
3. There is a high number of invalid responses 
"""

# Finalize the Variables we want and drop NAs

vars = list()
for i in range(len(variables)):
    var = list(data_dict.keys())[list(data_dict.values()).index(variables[i])]
    vars.append(var)
vars = vars+['HFUEL_target']
#vars = vars_final+['HFUEL_target']
final_data0 = df_all[vars]

final_data0.isna().sum()

"""We have 18 features (minus our target variable and identification features)

### Merge cleaned NHS dataset with Charging station dataset
"""

# Merging Charging Stations Counts to Final Dataset
charging_stations['counts'] = charging_stations['State'].map(charging_stations['State'].value_counts())
charging_stations = charging_stations[['counts', 'State']]
charging_stations = charging_stations.drop_duplicates('State').reset_index(drop = True)
final_data = final_data0.rename(columns = {'HHSTATE':'State'})
final_data = pd.merge(final_data, charging_stations[['State', 'counts']], on = ['State'], how = 'left')
final_data1 = final_data.rename(columns = {'counts':'CHARSTACT'}) #Charging Station Count

print(final_data1.shape)

"""### Simplifying variables code categories in preparation for One-Hot Encoding"""

#Remove rows with invalid response choices
#df=final_data1.copy()
#for var in final_data1.columns:
#    df.drop(df[df[var].isin(invalid)].index, inplace = True)
#print(df.shape)
#final_data2=df.copy()
#final_data2['HFUEL_target'].value_counts()

#Look at the distinct values/categories in each variable
#df.apply(np.unique,axis=0)
#final_data=df.copy()
#final_data2.apply(np.unique,axis=0)

#Look at the NaN values
#final_data2.isna().sum()

"""#### Determine the numerical vs categorical variables"""

#Numerical columns
num_var=['HHVEHCNT', 'WRKCOUNT','GSCOST', 'R_AGE_IMP', 'RIDESHARE','CHARSTACT']
#Categorical columns
cat_var=['HOMEOWN', 'HHFAMINC', 'State', 'URBANSIZE', 'EDUC','R_SEX_IMP', 'R_RACE','PHYACT', 'WEBUSE17',
       'PRICE', 'HFUEL_target']

#Create a df for the categorical variable dictionaries for easy access
cat_df = pd.DataFrame()
for var in cat_var:
    df=codebook_clean[codebook_clean['Name']==var]
    df=df.drop(['Name','Label','Type','Length','Frequency','Weighted'],axis=1)
    df=df.apply(pd.to_numeric, errors='ignore',axis=0)
    cat_df[var]=[df.set_index('Code')['Meaning'].to_dict()]
cat_df

"""### Look at the variables and how we can simplify them"""

# Household Family income
cat_df['HOMEOWN'][0]
#Add variable for minimum income level, derived from HHFAMINC
HOMEOWN={-8: 'Not Own',
 -7: 'Not Own',
 1: 'Own',
 2: 'Not Own',
 97: 'Not Own'}

# Household Family income
cat_df['HHFAMINC'][0]
#Add variable for minimum income level, derived from HHFAMINC
HHFAMINC={
    -9: None,
 -8: None,
 -7: None,
    1: 0,
 2: 10000,
 3: 15000,
 4: 25000,
 5: 35000,
 6: 50000,
 7: 75000,
 8: 100000,
 9: 125000,
 10: 150000,
 11: 200000}

#Add variable for minimum city population, derived from URBANSIZE
cat_df['URBANSIZE'][0]
URBANSIZE={
1: 50000,
 2: 200000,
 3: 500000,
 4: 1000000,
 5: 1000000,
 6: 0}

cat_df['EDUC'][0]
#Add variable for simplied education level, derived from EDUC
EDUC={
    -8: None,
 -7: None,
 -1: None,
1: '<=High school',
 2: '<=High school',
 3: "College degree",
 4: "College degree",
 5: 'Advanced degree'}

cat_df['R_SEX_IMP'][0]
R_SEX_IMP={1: 'Male', 2: 'Female'}

cat_df['R_RACE'][0]
R_RACE={-8: None,
 -7: None,
 1: 'White',
 2: 'Black',
 3: 'Asian',
 4: 'Other',
 5: 'Other',
 6: 'Other',
 97: 'Other'}

# Amount of physcial activity
cat_df['PHYACT'][0]
PHYACT={
    -9: 'Little',
 -8: 'Little',
 -7: 'Little',
 1: 'Little',
 2: 'Moderate',
 3: 'Vigorous'}

#How often use the web
cat_df['WEBUSE17'][0]
WEBUSE17={
    -9: None,
 -7: None,
 1: 'Frequent',
 2: 'Frequent',
 3: 'Infrequent',
 4: 'Infrequent',
 5: 'Infrequent'}

# Question if Price of Gasoline Affects Travel
cat_df['PRICE'][0]
PRICE={
    -9: None,
 -8: None,
 -7: None,
 1: 'YES',
 2: 'YES',
 3: 'NEUTRAL',
 4: 'NO',
 5: 'NO'}

changed_cat_vars=['HOMEOWN','HHFAMINC','URBANSIZE','EDUC','R_SEX_IMP','R_RACE','PHYACT','WEBUSE17','PRICE']
changed_var_dict=[HOMEOWN, HHFAMINC, URBANSIZE, EDUC,R_SEX_IMP, R_RACE,PHYACT, WEBUSE17,PRICE]

#dict_vars=[Min_Fam_Inc,Min_city_pop,Educ_lev,Race,Exercise,Web_use,Gas_price_effect]
#new_vars=['Min_Fam_Inc','Min_city_pop','Educ_lev','Race','Exercise','Web_use','Gas_price_effect']
#d['new'] = d['new'].fillna('Else')

changed_var_dict[1].get(-9)

df=final_data1.copy()
for i in range(len(changed_cat_vars)):
    #df[new_vars[i]] = np.nan
    var_dict=changed_var_dict[i]
    for key in var_dict.keys():
        df[changed_cat_vars[i]].mask(df[changed_cat_vars[i]] == key, var_dict.get(key), inplace=True)
        
#Rename columns
df.rename(columns={'HHFAMINC': 'Min_Fam_Inc', 'URBANSIZE': 'Min_city_pop','R_SEX_IMP': 'Gender',
                   'PHYACT':'Exercise','WEBUSE17':'Web_use','PRICE':'Gas_price_effect'}, inplace=True)
df

"""Generation definitions: <br>
Source: https://web.archive.org/web/20180331061858/https://www.pewresearch.org/topics/generations-and-age/
Age in 2018:
- Gen Z: 1997 – 2012 Age: 5 – 21
- Millennials: 1981-96 Age: 22-37
- Gen X: 1965-1980 Age: 38-53
- Boomers: 1946-1964 Age: 54-72
- Silent: 1928-1945 Age: 73-90
"""

df['Generation'] = pd.cut(df['R_AGE_IMP'], bins = [0,21,37,53,72,100], right = False, labels = ['Gen Z', 'Millennials', 'Gen X','Boomers','Silent'])       
#df['EV']=np.zeros()
#df['EV'].mask(df[HFUEL_target] == 1, 'EV', inplace=True)
final_data2=df.copy()

#check for NaN values: 449 rows, relatively small compared with total number of sample: 33,000+ rows, therefore, drop NaN
final_data2.isna().sum(axis=0) #449
final_data3=final_data2.dropna()
final_data3.shape 
final_data=final_data3.drop(columns=['HOUSEID', 'PERSONID'])

# Try filling the NaN with the mode, Decided not to
#df=final_data2.fillna(final_data2.mode().iloc[0])
#df.isna().sum()## convert df to a series
#final_data=df.copy()

#Original EVs=1315, after dropNaN EVs= 1305, so preserved most of the EVs
print(final_data.shape)
final_data['HFUEL_target'].value_counts()

# Dataset without One Hot Encoding
final_data.shape

#Data description :
final_data.describe()

#Description of variables by outcome (mean (sd)): 
final_data.groupby(["HFUEL_target"]).describe()
#final_data.groupby(["HFUEL_target"])[["OD_READ","HOMEOWN","HHVEHCNT","HHFAMINC", "WRKCOUNT","URBANSIZE","GSCOST","R_AGE_IMP","EDUC","R_RELAT","R_SEX_IMP","R_RACE","RIDESHARE", "PHYACT","WEBUSE17", "PRICE"]].describe()

#Variable count by outcome: 
barplot_var=['HOMEOWN', 'EDUC', 'Gender', 'R_RACE','Exercise', 'Web_use', 'Gas_price_effect','Generation']

for var in barplot_var:
    ct=pd.crosstab(final_data['HFUEL_target'],final_data[var],margins=False,normalize='index')
    # now stack and reset
    stacked = ct.stack().reset_index().rename(columns={0:'Percent'})
    # plot grouped bar chart
    plt.figure(figsize=(12,5))
    plt.title(var)
    p = sns.barplot(hue=stacked[var], y=stacked.Percent, x=stacked['HFUEL_target'])
    #sns.move_legend(p, bbox_to_anchor=(1, 1.02), loc='upper left')

"""### One Hot Encoding"""

# One Hot Encoded Data with state
ohe_vars=['HOMEOWN', 'State', 'EDUC', 'Gender', 'R_RACE','Exercise', 'Web_use', 'Gas_price_effect','Generation']
# One Hot Encoded Data with out state
#ohe_vars=['HOMEOWN', 'EDUC', 'Gender', 'R_RACE','Exercise', 'Web_use', 'Gas_price_effect','Generation']
ohe_final_data = pd.get_dummies(final_data, columns=ohe_vars,dtype=int)
ohe_final_data.head()

ohe_final_data.describe()

ohe_final_data.columns

"""### Export final data and one hot encoded data to .csv"""

### Export final data and one hot encoded data to .csv
#final_data.to_csv('final_data.csv',index=False)
#ohe_final_data.to_csv('ohe_final_data.csv',index=False)

# Dataset with One Hot Encoded Categorical Vars
ohe_final_data.shape

# Looking at Highly Correlated Features
corr_matrix = ohe_final_data.corr().abs()
print(corr_matrix['HFUEL_target'].sort_values(ascending = False).head(20))
#corr_matrix

"""There are no variables highly correlated to HFUEL (Our target variable). CA seems to be a slight positive correlation with buying an EV."""

#High level heat map to display correlation
plt.figure(figsize = (12,8))
corrplot = sns.heatmap(ohe_final_data.corr())
corrplot.set_xticklabels(corrplot.get_xticklabels(), rotation = 45, horizontalalignment = 'right') #For X axis labels
plt.show()

# OHE Heat Map
corr_matrix_ohe = ohe_final_data.corr().abs()
fig, ax = plt.subplots(figsize=(30,20)) 
sns.heatmap(corr_matrix_ohe, annot = True, linewidths = 0.5, ax=ax)

"""Proportions of different variables by outcome of interest 

"""

#Boxplot EV adoption vs. age: 
sns.boxplot(x = "HFUEL_target", y='R_AGE_IMP', data = final_data)
plt.title("Boxplot of EV adoption vs. Age")

#Boxplot EV adoption vs. count of household vehicle:
sns.boxplot(x = "HFUEL_target", y='HHVEHCNT', data = final_data)
plt.title("Boxplot of EV adoption vs. count of household vehicle")

#Boxplot EV adoption vs. number of workers in household:
sns.boxplot(x = "HFUEL_target", y='WRKCOUNT', data = final_data)
plt.title("Boxplot of EV adoption vs. number of workers in household")

#Boxplot EV adoption vs. fuel cost in US:
sns.boxplot(x = "HFUEL_target", y='GSCOST', data = final_data)
plt.title("Boxplot of EV adoption vs. fuel cost in US")

#Boxplot EV adoption vs. count of ride share:
sns.boxplot(x = "HFUEL_target", y='RIDESHARE', data = final_data)
plt.title("Boxplot of EV adoption vs. count of ride share")

"""Perform chi-square test to test for any significance difference between variables and the outcome

scipy.stats.chi2_contingency, from Scipy:
<br>
"Chi-square test of independence of variables in a contingency table"
In this test you are testing if there is there is relationship between two or more variable. This is called chi-square test for independence, also called Pearson's chi-square test or the chi-square test of association. In this test you are testing the association between two or more variable. The null hupothesis, in your example, is "there is no effect of group in choosing the equipment to use".
<br>
In scipy.stats.chisquare from Scipy
<br>
"The chi square test tests the null hypothesis that the categorical data has the given frequencies."
Here you are comparing if there is difference between an observation and an expected frequency. So, the null hupothesis, is that "there isn't any difference between observed and the expected". Here, the test is used to compare the observed sample distribution with the expected probability distribution. This is named Chi-Square goodness of fit test
<br>
let alpha=0.05 (significance level)<br>
A small p (≤ 0.05), reject the null hypothesis. This is strong evidence that the null hypothesis is invalid.
A large p (> 0.05) means the alternate hypothesis is weak, so you do not reject the null.
"""

data_crosstab = pd.crosstab(final_data['HFUEL_target'],
                            final_data['HOMEOWN'],
                           margins=True, margins_name="Total")

data_crosstab

p_vals=[]
var_names=[]
for column in final_data.columns:
    data_crosstab = pd.crosstab(final_data['HFUEL_target'],
                            final_data[column],
                           margins=True, margins_name="Total")
    c, p, dof, expected = stats.chi2_contingency(data_crosstab) 
    p_vals.append(p)
    var_names.append(column)
Chi2_table=pd.DataFrame({'var_names':var_names,'p_vals':p_vals})
alpha=0.05
Chi2_table['sig']=Chi2_table['p_vals'].apply(lambda x: 'dependent' if x<=alpha else 'independent')

#df['equal_or_lower_than_4?'] = df['set_of_numbers'].apply(lambda x: 'True' if x <= 4 else 'False')
Chi2_table

"""Independent t-test"""

#p_vals=[]
#var_names=[]
#for column in final_data.columns:
 # a=np.array(final_data[final_data['HFUEL_target']==1][column])
  #b=np.array(final_data[final_data['HFUEL_target']==0][column])
  #statistic, pvalue=stats.ttest_ind(a,b)
  #p_vals.append(pvalue)
  #var_names.append(column)
#ttest_table=pd.DataFrame({'var_names':var_names,'p_vals':p_vals})
#alpha=0.05
#ttest_table['sig']=ttest_table['p_vals'].apply(lambda x: 'dependent' if x<=alpha else 'independent')
#ttest_table

"""### Data Segmentation for ML
Top 7 states for EV Penetration: <br>
Hawaii, HI <br>
California, CA <br>
New Mexico, NM <br>
District of Columbia, DC <br>
Connecticut, CT <br>
New Hampshire, NH <br>
Massachusetts, MA (tied)

"""

final_data.columns

# Labeling the Data in High EV states
high_ev = ['DC', 'CA', 'HI', 'NM', 'CT']

#Adding a column to indicate if a person is in a high EV penetration state
ml_data=final_data.copy()
ml_data['high_ev_state'] = np.where(ml_data['State'].isin(high_ev),1,0)

# Segmenting the Data
high_ev_dat = final_data[final_data['State'].isin(high_ev)]
low_ev_dat = final_data[~final_data['State'].isin(high_ev)]

#drop state and age columns
ml_data.drop(['State', 'R_AGE_IMP'], axis = 1, inplace = True)
high_ev_dat.drop(['State', 'R_AGE_IMP'], axis = 1, inplace = True)
low_ev_dat.drop(['State', 'R_AGE_IMP'], axis = 1, inplace = True)

#LabelEncoder assigns numbers to each string category
#pd.get_dummies creates new column (one hot encoded) for each category
#transform the home ownership column
#high_ev_dat['HOMEOWN'] = LabelEncoder().fit_transform(high_ev_dat['HOMEOWN'])
#low_ev_dat['HOMEOWN'] = LabelEncoder().fit_transform(low_ev_dat['HOMEOWN'])
#high_ev_dat['R_RACE'] = LabelEncoder().fit_transform(high_ev_dat['R_RACE'])
#low_ev_dat['R_RACE'] = LabelEncoder().fit_transform(low_ev_dat['R_RACE'])

# Overall Ev Penetration
100*len(ml_data[ml_data['HFUEL_target'] == 1])/ml_data['HFUEL_target'].value_counts().sum()

# High Ev Penetration
100*len(high_ev_dat[high_ev_dat['HFUEL_target'] == 1])/high_ev_dat['HFUEL_target'].value_counts().sum()

# Low EV Penetration
100*len(low_ev_dat[low_ev_dat['HFUEL_target'] == 1])/low_ev_dat['HFUEL_target'].value_counts().sum()

# Segmented One Hot Encoded Data without state
ohe_vars=['HOMEOWN','EDUC', 'Gender', 'R_RACE','Exercise', 'Web_use', 'Gas_price_effect','Generation']

#One hot encode
ohe_ml_data = pd.get_dummies(ml_data, columns=ohe_vars,dtype=int)
high_ev_dat_ohe = pd.get_dummies(high_ev_dat, columns=ohe_vars,dtype=int)
low_ev_dat_ohe = pd.get_dummies(low_ev_dat, columns=ohe_vars,dtype=int)

#drop one of each of the binary category columns
bin_vars=['HOMEOWN_Not Own', 'Gender_Female','Web_use_Infrequent']
ohe_ml_data.drop(bin_vars, axis = 1, inplace = True)
high_ev_dat_ohe.drop(bin_vars, axis = 1, inplace = True)
low_ev_dat_ohe.drop(bin_vars, axis = 1, inplace = True)

ohe_ml_data.columns

"""### Demographic variables
'HHVEHCNT',
'Min_Fam_Inc', 
'WRKCOUNT', 
'RIDESHARE',
'HOMEOWN_Own', 
'EDUC_<=High school', 
'EDUC_Advanced degree',
'EDUC_College degree', 
'Gender_Male', 
'R_RACE_Asian', 
'R_RACE_Black',
'R_RACE_Other', 
'R_RACE_White', 
'Exercise_Little', 
'Exercise_Moderate',
'Exercise_Vigorous', 
'Web_use_Frequent', 
'Gas_price_effect_NEUTRAL',
'Gas_price_effect_NO', 
'Gas_price_effect_YES', 
'Generation_Gen Z',
'Generation_Millennials', 
'Generation_Gen X', 
'Generation_Boomers',
'Generation_Silent'
       
### Geographic/policy variables
'Min_city_pop', 
'GSCOST',
'high_ev_state'

# Predicting without segmentation
Drop the 'state' and 'high_ev_state' identifiers and see if we can predict without knowing the location of the person <br>
Baseline model
"""

ohe_ml_data.drop(['high_ev_state', 'HOMEOWN_Own', 'WRKCOUNT', 'RIDESHARE'], axis = 1, inplace = True)
len(ohe_ml_data.columns)

#Separate the features from the target variable
X_unba=ohe_ml_data.drop(['HFUEL_target'], axis = 1)
y_unba=ohe_ml_data['HFUEL_target']

#Scale the feature data
scaler = MinMaxScaler()
X = scaler.fit_transform(X_unba)
y = y_unba

#Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# models to fit

models = [LogisticRegression(max_iter=500),svm.LinearSVC(),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()] 
model_names = ['LogisticRegression()','svm.LinearSVC()','RandomForestClassifier()','DecisionTreeClassifier()', 'GaussianNB()'] 

f1_macro=[]
accuracy=[]
precision=[]
recall=[]
auc=[]
cm=[]
for model in models:
    clf=model
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=0.5)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # fit the model
    clf.fit(X_resample, y_resample)
    y_pred = clf.predict(X_test)
    # look at metrics
    f1_macro.append(f1_score(y_test, y_pred, average='macro'))
    accuracy.append(accuracy_score(y_test, y_pred))
    precision.append(precision_score(y_test, y_pred, average='weighted'))
    recall.append(recall_score(y_test, y_pred, average='weighted'))
    auc.append(roc_auc_score(y_test, y_pred))
    cm.append(confusion_matrix(y_test, y_pred))

unb_test_metric_df=pd.DataFrame({'model': model_names, 'f1_macro':f1_macro,'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'AUC':auc})
unb_test_metric_df

"""### Data Imbalance treatment
Synthetic Minority Oversampling Technique
"""

#Separate the features from the target variable
X_all=ohe_ml_data.drop(['HFUEL_target'], axis = 1)
y_all=ohe_ml_data['HFUEL_target']

#Scale the feature data
scaler = MinMaxScaler()
X = scaler.fit_transform(X_all)
y = y_all

#Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

y_test_all =y_test

# summarize class distribution
y=[y_all,y_train, y_test]
for data in y:
    counter = Counter(data)
    print(counter)

"""### Use SMOTE to over and under sample for a more balanced dataset
E.g. for a sample of 10,000:100: first oversample the minority class to have 10 percent the number of examples of the majority class (e.g. about 1,000), then use random undersampling to reduce the number of examples in the majority class to have 50 percent more than the minority class (e.g. about 2,000).
"""

# values to evaluate
# default k_neighbors=5
# (over,under)
# best over sampling_strategy=0.4 (0.1,0.1), (0.2,0.2), (0.3,0.6, 0.789), (0.4,0.5, 0.79),(0.5,0.5, 0.79)
# best under sampling_strategy=0.4

#k_values = [1, 2, 3, 4, 5, 6, 7]
k_values = [0.4,0.5,0.6,0.7,0.8,0.9]
#k_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,0.8,0.9]

for k in k_values:
    # define pipeline
    model = LogisticRegression()
    #model = DecisionTreeClassifier()
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=k)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # evaluate pipeline using cross validation
    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
    # look at AUC score
    scores = cross_val_score(model, X_resample, y_resample, scoring='roc_auc', cv=cv, n_jobs=-1)
    score = np.mean(scores)
    print('> k=%.1f, Mean ROC AUC: %.3f' % (k, score))
    counter = Counter(y_resample)
    print(counter)

"""Find optimal sampling strategy for basic Logistic Regression model <br>
Solution <br>
best over sampling_strategy=0.4 <br>
best under sampling_strategy=0.5 <br>
k_neighbors=5 (default)

### Logistic Regression
models = [LogisticRegression(),svm.SVC(kernel='linear', probability=True),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()]
"""

# models to evaluate
# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

model = LogisticRegression()
over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
under = RandomUnderSampler(sampling_strategy=0.5)
steps = [('over', over), ('under', under)]
# define pipeline
pipeline = Pipeline(steps=steps)
# transform the dataset
X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
# evaluate pipeline using cross validation
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
# look at AUC score
scores = cross_val_score(model, X_resample, y_resample, scoring='roc_auc', cv=cv, n_jobs=-1)
score = np.mean(scores)
print('> model: LogisticRegression(), Mean ROC AUC: %.3f' % (score))

"""### All models

F1 Score,Accuracy ,Precision,Recall,AUC <br>
F1 Score: 'f1_macro' <br>
'macro': does not take label imbalance into account.
'weighted': alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.
Accuracy: 'accuracy'
Precision: 'precision'
Recall: 'recall'
AUC:‘roc_auc’
"""

# models to evaluate
# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

models = [LogisticRegression(max_iter=500),svm.LinearSVC(),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()] 
model_names = ['LogisticRegression()','svm.LinearSVC()','RandomForestClassifier()','DecisionTreeClassifier()', 'GaussianNB()'] 

f1_macro=[]
accuracy=[]
precision=[]
recall=[]
auc=[]
for model in models:
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=0.5)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # evaluate pipeline using cross validation
    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
    # look at metrics
    f1_macro.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='f1_macro', cv=cv, n_jobs=-1)))
    accuracy.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='accuracy', cv=cv, n_jobs=-1)))
    precision.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='precision', cv=cv, n_jobs=-1)))
    recall.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='recall', cv=cv, n_jobs=-1)))
    auc.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='roc_auc', cv=cv, n_jobs=-1)))

metric_df=pd.DataFrame({'model': model_names, 'f1_macro':f1_macro,'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'AUC':auc})
metric_df

# models to fit

models = [LogisticRegression(),svm.LinearSVC(),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()] 
model_names = ['LogisticRegression()','svm.LinearSVC()','RandomForestClassifier()','DecisionTreeClassifier()', 'GaussianNB()'] 

f1_macro=[]
accuracy=[]
precision=[]
recall=[]
auc=[]
cm=[]
for model in models:
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=0.5)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # fit the model
    model.fit(X_resample, y_resample)
    y_pred = model.predict(X_test)
    # look at metrics
    f1_macro.append(f1_score(y_test, y_pred, average='macro'))
    accuracy.append(accuracy_score(y_test, y_pred))
    precision.append(precision_score(y_test, y_pred, average='weighted'))
    recall.append(recall_score(y_test, y_pred, average='weighted'))
    auc.append(roc_auc_score(y_test, y_pred))
    cm.append(confusion_matrix(y_test, y_pred))

test_metric_df=pd.DataFrame({'model': model_names, 'f1_macro':f1_macro,'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'AUC':auc})
test_metric_df

"""### Random forest is best model, optimize for all data below:"""

# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

#Fit Random forest model on balanced data
over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
under = RandomUnderSampler(sampling_strategy=0.5)
steps = [('over', over), ('under', under)]
# define pipeline
pipeline = Pipeline(steps=steps)
# transform the dataset
X_resample, y_resample = pipeline.fit_resample(X_train, y_train)

# grid search
from sklearn.model_selection import RandomizedSearchCV

hyper_params={
    
    'max_depth':range(3,20),
    'max_features':range(3,37),
    'min_samples_leaf': range(20,400,50),
    'n_estimators':range(10,101,10)
}

rf_rcv=RandomizedSearchCV(estimator=RandomForestClassifier(),
                          param_distributions=hyper_params,
                          verbose=1,
                          cv=5,
                          return_train_score=True,
                          n_jobs=-1, 
                          n_iter=50)
rf_rcv.fit(X_resample, y_resample)
rf_rcv.best_estimator_

# feature importance
#high_ev_dat_ohe_train=high_ev_dat_ohe.drop(columns=label_var)

rf_feature_importance=pd.DataFrame(rf_rcv.best_estimator_.feature_importances_,index=X_all.columns).reset_index()
rf_feature_importance.columns=['feature','importance']
rf_feature_importance.sort_values(ascending=False, by='importance').head(10)
#y_pred_rf = rf_rcv.predict(X_test)

y_pred_all_rf = rf_rcv.predict(X_test)

"""### Predicting on ENTIRE dataset"""

y_pred = rf_rcv.predict(X)

X.shape

y_pred.sum()

y_all.sum()

"""# Predicting with segmentation in high and low (everything else) EV adoption states
Separate the data and see if we can predict each person in each regiong<br>
2 segmented models
### High EV penetration states
"""

#Separate the features from the target variable
X_high=high_ev_dat_ohe.drop(['HFUEL_target', 'HOMEOWN_Own', 'WRKCOUNT', 'RIDESHARE'], axis = 1) #low_ev_dat_ohe
y_high=high_ev_dat_ohe['HFUEL_target']

#Scale the feature data
scaler = MinMaxScaler()
X = scaler.fit_transform(X_high)
y = y_high

#Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

y_test_high =y_test

# summarize class distribution
y=[y_high,y_train, y_test]
for data in y:
    counter = Counter(data)
    print(counter)

# models to evaluate
# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

models = [LogisticRegression(),svm.LinearSVC(),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()] 
model_names = ['LogisticRegression()','svm.LinearSVC()','RandomForestClassifier()','DecisionTreeClassifier()', 'GaussianNB()'] 

f1_macro=[]
accuracy=[]
precision=[]
recall=[]
auc=[]
for model in models:
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=0.5)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # evaluate pipeline using cross validation
    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
    # look at metrics
    f1_macro.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='f1_macro', cv=cv, n_jobs=-1)))
    accuracy.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='accuracy', cv=cv, n_jobs=-1)))
    precision.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='precision', cv=cv, n_jobs=-1)))
    recall.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='recall', cv=cv, n_jobs=-1)))
    auc.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='roc_auc', cv=cv, n_jobs=-1)))

high_metric_df=pd.DataFrame({'model': model_names, 'f1_macro':f1_macro,'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'AUC':auc})
high_metric_df

# models to fit

models = [LogisticRegression(),svm.LinearSVC(),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()] 
model_names = ['LogisticRegression()','svm.LinearSVC()','RandomForestClassifier()','DecisionTreeClassifier()', 'GaussianNB()'] 

f1_macro=[]
accuracy=[]
precision=[]
recall=[]
auc=[]
cm=[]
for model in models:
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=0.5)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # fit the model
    model.fit(X_resample, y_resample)
    y_pred = model.predict(X_test)
    # look at metrics
    f1_macro.append(f1_score(y_test, y_pred, average='macro'))
    accuracy.append(accuracy_score(y_test, y_pred))
    precision.append(precision_score(y_test, y_pred, average='weighted'))
    recall.append(recall_score(y_test, y_pred, average='weighted'))
    auc.append(roc_auc_score(y_test, y_pred))
    cm.append(confusion_matrix(y_test, y_pred))

high_test_metric_df=pd.DataFrame({'model': model_names, 'f1_macro':f1_macro,'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'AUC':auc})
high_test_metric_df

"""### Random forest is best model, optimize for all data below:"""

# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

#Fit Random forest model on balanced data
over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
under = RandomUnderSampler(sampling_strategy=0.5)
steps = [('over', over), ('under', under)]
# define pipeline
pipeline = Pipeline(steps=steps)
# transform the dataset
X_resample, y_resample = pipeline.fit_resample(X_train, y_train)

# grid search
from sklearn.model_selection import RandomizedSearchCV

hyper_params={
    
    'max_depth':range(3,20),
    'max_features':range(3,37),
    'min_samples_leaf': range(20,400,50),
    'n_estimators':range(10,101,10)
}

rf_rcv=RandomizedSearchCV(estimator=RandomForestClassifier(),
                          param_distributions=hyper_params,
                          verbose=1,
                          cv=5,
                          return_train_score=True,
                          n_jobs=-1, 
                          n_iter=50)
rf_rcv.fit(X_resample, y_resample)
rf_rcv.best_estimator_

# feature importance
#high_ev_dat_ohe_train=high_ev_dat_ohe.drop(columns=label_var)

rf_feature_importance=pd.DataFrame(rf_rcv.best_estimator_.feature_importances_,index=X_high.columns).reset_index()
rf_feature_importance.columns=['feature','importance']
rf_feature_importance.sort_values(ascending=False, by='importance').head(10)
#y_pred_rf = rf_rcv.predict(X_test)

y_pred_high_rf = rf_rcv.predict(X_test)

"""### Low EV penetration states"""

#Separate the features from the target variable
X_low=low_ev_dat_ohe.drop(['HFUEL_target', 'HOMEOWN_Own', 'WRKCOUNT', 'RIDESHARE'], axis = 1) #low_ev_dat_ohe
y_low=low_ev_dat_ohe['HFUEL_target']

#Scale the feature data
scaler = MinMaxScaler()
X = scaler.fit_transform(X_low)
y = y_low

#Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
y_test_low =y_test

# summarize class distribution
y=[y_low,y_train, y_test]
for data in y:
    counter = Counter(data)
    print(counter)

# models to evaluate
# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

models = [LogisticRegression(),svm.LinearSVC(),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()] 
model_names = ['LogisticRegression()','svm.LinearSVC()','RandomForestClassifier()','DecisionTreeClassifier()', 'GaussianNB()'] 

f1_macro=[]
accuracy=[]
precision=[]
recall=[]
auc=[]
for model in models:
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=0.5)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # evaluate pipeline using cross validation
    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
    # look at metrics
    f1_macro.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='f1_macro', cv=cv, n_jobs=-1)))
    accuracy.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='accuracy', cv=cv, n_jobs=-1)))
    precision.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='precision', cv=cv, n_jobs=-1)))
    recall.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='recall', cv=cv, n_jobs=-1)))
    auc.append(np.mean(cross_val_score(model, X_resample, y_resample, scoring='roc_auc', cv=cv, n_jobs=-1)))

high_metric_df=pd.DataFrame({'model': model_names, 'f1_macro':f1_macro,'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'AUC':auc})
high_metric_df

# models to fit

models = [LogisticRegression(),svm.LinearSVC(),RandomForestClassifier(),DecisionTreeClassifier(), GaussianNB()] 
model_names = ['LogisticRegression()','svm.LinearSVC()','RandomForestClassifier()','DecisionTreeClassifier()', 'GaussianNB()'] 

f1_macro=[]
accuracy=[]
precision=[]
recall=[]
auc=[]
cm=[]
for model in models:
    over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
    under = RandomUnderSampler(sampling_strategy=0.5)
    steps = [('over', over), ('under', under)]
    # define pipeline
    pipeline = Pipeline(steps=steps)
    # transform the dataset
    X_resample, y_resample = pipeline.fit_resample(X_train, y_train)
    # fit the model
    model.fit(X_resample, y_resample)
    y_pred = model.predict(X_test)
    # look at metrics
    f1_macro.append(f1_score(y_test, y_pred, average='macro'))
    accuracy.append(accuracy_score(y_test, y_pred))
    precision.append(precision_score(y_test, y_pred, average='weighted'))
    recall.append(recall_score(y_test, y_pred, average='weighted'))
    auc.append(roc_auc_score(y_test, y_pred))
    cm.append(confusion_matrix(y_test, y_pred))

low_test_metric_df=pd.DataFrame({'model': model_names, 'f1_macro':f1_macro,'Accuracy': accuracy, 'Precision': precision,'Recall': recall, 'AUC':auc})
low_test_metric_df

"""### Random forest is best model, optimize for all data below:"""

# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

#Fit Random forest model on balanced data
over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
under = RandomUnderSampler(sampling_strategy=0.5)
steps = [('over', over), ('under', under)]
# define pipeline
pipeline = Pipeline(steps=steps)
# transform the dataset
X_resample, y_resample = pipeline.fit_resample(X_train, y_train)

# grid search
from sklearn.model_selection import RandomizedSearchCV

hyper_params={
    
    'max_depth':range(3,20),
    'max_features':range(3,37),
    'min_samples_leaf': range(20,400,50),
    'n_estimators':range(10,101,10)
}

rf_rcv=RandomizedSearchCV(estimator=RandomForestClassifier(),
                          param_distributions=hyper_params,
                          verbose=1,
                          cv=5,
                          return_train_score=True,
                          n_jobs=-1, 
                          n_iter=50)
rf_rcv.fit(X_resample, y_resample)
rf_rcv.best_estimator_

# feature importance
#high_ev_dat_ohe_train=high_ev_dat_ohe.drop(columns=label_var)

rf_feature_importance=pd.DataFrame(rf_rcv.best_estimator_.feature_importances_,index=X_all.columns).reset_index()
rf_feature_importance.columns=['feature','importance']
rf_feature_importance.sort_values(ascending=False, by='importance').head(10)
#y_pred_rf = rf_rcv.predict(X_test)

y_pred_low_rf = rf_rcv.predict(X_test)

# plot lines for model comparison
import sklearn.metrics
fpr, tpr, thr=sklearn.metrics.roc_curve(y_test_all, y_pred_all_rf)
fpr_l, tpr_l, thr_l=sklearn.metrics.roc_curve(y_test_low, y_pred_low_rf)
fpr_h, tpr_h, thr_h=sklearn.metrics.roc_curve(y_test_high,y_pred_high_rf)

plt.title('Basic and Segmented Random Forest Model ROC Curve')
plt.plot(fpr,tpr, color='black',label='Basic model (area = %0.2f)' % sklearn.metrics.roc_auc_score(y_test_all, y_pred_all_rf))
plt.plot(fpr_l,tpr_l, color='red',label='Low EV states model (area = %0.2f)' % sklearn.metrics.roc_auc_score(y_test_low, y_pred_low_rf))
plt.plot(fpr_h,tpr_h, color='blue',label='High EV states model (area = %0.2f)' % sklearn.metrics.roc_auc_score(y_test_high, y_pred_high_rf))
plt.plot([0, 1], [0, 1],'r--')
plt.ylim([0, 1]);
plt.xlabel("False Postive rate (FPR)");
plt.ylabel("True Postive rate (TPR)");
plt.legend(loc="lower right")
#plt.savefig('RF_ROC')
plt.show()

print("AUC on TEST for Basic NB: %.3f" % (sklearn.metrics.roc_auc_score(y_test_all, y_pred_all_rf))) 
print("AUC on TEST for Low EV states: %.3f" % (sklearn.metrics.roc_auc_score(y_test_low, y_pred_low_rf)))
print("AUC on TEST for High EV states: %.3f" % (sklearn.metrics.roc_auc_score(y_test_high,y_pred_high_rf)))

"""### Confusion Matrices"""

cm_all=confusion_matrix(y_test_all, y_pred_all_rf)
cm_low=confusion_matrix(y_test_low, y_pred_low_rf)
cm_high=confusion_matrix(y_test_high,y_pred_high_rf)

for cm in [cm_all,cm_low,cm_high]:
    cm_df = pd.DataFrame(data=cm, columns=[0, 1], index=[0, 1])
    cm_df.columns.name = 'Predicted'
    cm_df.index.name = 'True'
    print(cm_df)

#can also try standardscaler instead of min max
#from sklearn.preprocessing import StandardScaler
#sc = StandardScaler()

#X_train = sc.fit_transform(X_train)
#X_test = sc.transform(X_test)

"""# Predicting on entire data state"""

ml_data.columns

ohe_ml_data.columns

"""### Data Imbalance treatment
Synthetic Minority Oversampling Technique
"""

#Separate the features from the target variable
X_all=ohe_ml_data.drop(['HFUEL_target'], axis = 1)
y_all=ohe_ml_data['HFUEL_target']

#Scale the feature data
scaler = MinMaxScaler()
X = scaler.fit_transform(X_all)
y = y_all

#Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

y_test_all =y_test

"""### Random forest (best model), optimize for all data below:"""

# default k_neighbors=5
# sampling_strategy: (over,under) = (0.4,0.5)

#Fit Random forest model on balanced data
over = SMOTE(sampling_strategy=0.4, k_neighbors=5)
under = RandomUnderSampler(sampling_strategy=0.5)
steps = [('over', over), ('under', under)]
# define pipeline
pipeline = Pipeline(steps=steps)
# transform the dataset
X_resample, y_resample = pipeline.fit_resample(X_train, y_train)

# grid search
from sklearn.model_selection import RandomizedSearchCV

hyper_params={
    
    'max_depth':range(3,20),
    'max_features':range(3,37),
    'min_samples_leaf': range(20,400,50),
    'n_estimators':range(10,101,10)
}

rf_rcv=RandomizedSearchCV(estimator=RandomForestClassifier(),
                          param_distributions=hyper_params,
                          verbose=1,
                          cv=5,
                          return_train_score=True,
                          n_jobs=-1, 
                          n_iter=50)
rf_rcv.fit(X_resample, y_resample)
rf_rcv.best_estimator_

# feature importance
#high_ev_dat_ohe_train=high_ev_dat_ohe.drop(columns=label_var)

rf_feature_importance=pd.DataFrame(rf_rcv.best_estimator_.feature_importances_,index=X_all.columns).reset_index()
rf_feature_importance.columns=['feature','importance']
rf_feature_importance.sort_values(ascending=False, by='importance').head(10)
#y_pred_rf = rf_rcv.predict(X_test)

y_pred = rf_rcv.predict(X)

cm=confusion_matrix(y, y_pred)
cm_all_df = pd.DataFrame(data=cm, columns=[0, 1], index=[0, 1])
cm_all_df.columns.name = 'Predicted'
cm_all_df.index.name = 'True'
print(cm_all_df)

print("AUC on TEST for all data: %.3f" % (sklearn.metrics.roc_auc_score(y, y_pred)))

y_pred.shape

final_data.shape

pred_df=final_data.copy()
pred_df['prediction']=y_pred
pred_df

### Export final data and one hot encoded data to .csv
pred_df.to_csv('pred_data.csv',index=False)

"""### Old code"""

#Logistic regression
X=ohe_ml_data.drop(label_var,axis=1)
y=ohe_ml_data[label_var]

logreg = LogisticRegression()
logreg.fit(X_train,y_train)
log_odds = logreg.coef_[0]

print("Training set score: {:.3f}".format(logreg.score(X_train,y_train)))
print("Test set score: {:.3f}".format(logreg.score(X_test,y_test)))

#Coefficient of logistic regression, or log odds
pd.DataFrame(log_odds, 
             X.columns, 
             columns=['coef'])\
            .sort_values(by='coef', ascending=False)
#Adjusted coefficients of logistic regression, or odds
odds = np.exp(logreg.coef_[0])
pd.DataFrame(odds, 
             X.columns, 
             columns=['coef'])\
            .sort_values(by='coef', ascending=False)

"""### Interpretation of 'odds' coefficients
“For every one-unit increase in [X variable], the odds that the observation is in (y class) are [coefficient] times as large as the odds that the observation is not in (y class) when all other variables are held constant.”

### p-value
A large p-value (> 0.05) indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis. p-values very close to the cutoff (0.05) are considered to be marginal (could go either way)
Null hypothesis is the baseline; i.e. change in variable has no effect on the target response

Significant variables are:<br>
Min_Fam_Inc <br>
Min_city_pop <br>
GSCOST <br>
CHARSTACT <br>
high_ev_state <br>
"""

pd.DataFrame(X_train,columns=X.columns)

#import statsmodels.api as sm
#regression without scaling
X=ohe_ml_data.drop(label_var,axis=1)
y=ohe_ml_data[label_var]

#logit_model=sm.Logit(y_train,X_train)
logit_model=sm.Logit(y,X)
result=logit_model.fit()
result.summary()

"""### Machine Learning"""

